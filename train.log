Compiling user custom op, it will cost a few seconds.....
cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++
W0805 16:17:12.896770  1380 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1
W0805 16:17:12.901535  1380 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.
PAConv(
  (scorenet1): ScoreNet(
    (mlp_convs_hidden): LayerList(
      (0): Conv2D(6, 16, kernel_size=[1, 1], data_format=NCHW)
      (1): Conv2D(16, 8, kernel_size=[1, 1], data_format=NCHW)
    )
    (mlp_bns_hidden): LayerList(
      (0): BatchNorm2D(num_features=16, momentum=0.1, epsilon=1e-05)
      (1): BatchNorm2D(num_features=8, momentum=0.1, epsilon=1e-05)
    )
  )
  (scorenet2): ScoreNet(
    (mlp_convs_hidden): LayerList(
      (0): Conv2D(6, 16, kernel_size=[1, 1], data_format=NCHW)
      (1): Conv2D(16, 8, kernel_size=[1, 1], data_format=NCHW)
    )
    (mlp_bns_hidden): LayerList(
      (0): BatchNorm2D(num_features=16, momentum=0.1, epsilon=1e-05)
      (1): BatchNorm2D(num_features=8, momentum=0.1, epsilon=1e-05)
    )
  )
  (scorenet3): ScoreNet(
    (mlp_convs_hidden): LayerList(
      (0): Conv2D(6, 16, kernel_size=[1, 1], data_format=NCHW)
      (1): Conv2D(16, 8, kernel_size=[1, 1], data_format=NCHW)
    )
    (mlp_bns_hidden): LayerList(
      (0): BatchNorm2D(num_features=16, momentum=0.1, epsilon=1e-05)
      (1): BatchNorm2D(num_features=8, momentum=0.1, epsilon=1e-05)
    )
  )
  (scorenet4): ScoreNet(
    (mlp_convs_hidden): LayerList(
      (0): Conv2D(6, 16, kernel_size=[1, 1], data_format=NCHW)
      (1): Conv2D(16, 8, kernel_size=[1, 1], data_format=NCHW)
    )
    (mlp_bns_hidden): LayerList(
      (0): BatchNorm2D(num_features=16, momentum=0.1, epsilon=1e-05)
      (1): BatchNorm2D(num_features=8, momentum=0.1, epsilon=1e-05)
    )
  )
  (bn1): BatchNorm1D(num_features=64, momentum=0.1, epsilon=1e-05, data_format=NCL)
  (bn2): BatchNorm1D(num_features=64, momentum=0.1, epsilon=1e-05, data_format=NCL)
  (bn3): BatchNorm1D(num_features=128, momentum=0.1, epsilon=1e-05, data_format=NCL)
  (bn4): BatchNorm1D(num_features=256, momentum=0.1, epsilon=1e-05, data_format=NCL)
  (bn5): BatchNorm1D(num_features=1024, momentum=0.1, epsilon=1e-05, data_format=NCL)
  (conv5): Sequential(
    (0): Conv1D(512, 1024, kernel_size=[1], data_format=NCL)
    (1): BatchNorm1D(num_features=1024, momentum=0.1, epsilon=1e-05, data_format=NCL)
  )
  (linear1): Linear(in_features=2048, out_features=512, dtype=float32)
  (bn11): BatchNorm1D(num_features=512, momentum=0.1, epsilon=1e-05, data_format=NCL)
  (dp1): Dropout(p=0.5, axis=None, mode=upscale_in_train)
  (linear2): Linear(in_features=512, out_features=256, dtype=float32)
  (bn22): BatchNorm1D(num_features=256, momentum=0.1, epsilon=1e-05, data_format=NCL)
  (dp2): Dropout(p=0.5, axis=None, mode=upscale_in_train)
  (linear3): Linear(in_features=256, out_features=40, dtype=float32)
)
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:654: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
[Train] epoch:0	batch id:0	 lr:0.099996 loss:6.797373
[Train] epoch:0	batch id:10	 lr:0.099996 loss:5.640864
[Train] epoch:0	batch id:20	 lr:0.099996 loss:4.914048
[Train] epoch:0	batch id:30	 lr:0.099996 loss:4.209501
[Train] epoch:0	batch id:40	 lr:0.099996 loss:3.746494
[Train] epoch:0	batch id:50	 lr:0.099996 loss:3.388948
[Train] epoch:0	batch id:60	 lr:0.099996 loss:3.415180
[Train] epoch:0	batch id:70	 lr:0.099996 loss:3.517714
